{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "\n",
    "#Twitter API credentials\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_key = \"\"\n",
    "access_secret = \"\"\n",
    "\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "#initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=100)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(\"getting tweets before %s\" % (oldest))\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "    \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "    \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "    \n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "    return outtweets\n",
    "    #write the csv\t\n",
    "    #with open('%s_tweets.csv' % screen_name, 'wb') as f:\n",
    "     #   writer = csv.writer(f)\n",
    "    #    writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "    #    writer.writerows(outtweets)\n",
    "    \n",
    "    #pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #pass in the username of the account you want to download\n",
    "    k=get_all_tweets(\"Sky_M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desired_tweets=['663286416676274176']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Converting array to dictionary\n",
    "ma={}\n",
    "for i in range(len(k)):\n",
    "    ma[k[i][0]]=k[i][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for j in range(len(m)):\n",
    "    print(\"Tweetid:\",m[j])\n",
    "    print(\"Text:\",ma[m[j]])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
